---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

($^*$ denotes alphabetical ordering or co-first author)

# Preprints


R. Zhang, J. Wu, **L. Lin**, P. L. Bartlett.
Minimax Optimal Convergence of Gradient Descent in Logistic Regression via Large and Adaptive Stepsizes. Preprint, 2025+. [arXiv](https://arxiv.org/abs/2504.04105)

**L. Lin**, S. Mei.
A Statistical Theory of Contrastive Learning via Approximate Sufficient Statistics. Preprint, 2025+. [arXiv](https://arxiv.org/abs/2503.17538)


X. Zhao, W. Cai, T. Shi, D. Huang, **L. Lin**, S. Mei, D. Song.
Improving LLM Safety Alignment with Dual-Objective Optimization. Preprint, 2025+. [arXiv](https://arxiv.org/abs/2503.03710)

K. Oko, **L. Lin***, Y. Cai, S. Mei.
A Statistical Theory of Contrastive Pre-training and Multimodal Generative AI. Preprint, 2025+. [arXiv](https://arxiv.org/abs/2501.04641)

**L. Lin***, F. Su, W. Mou, P. Ding, M. J. Wainwright.
When is it worthwhile to jackknife? Breaking the quadratic barrier for Z-estimators. Preprint, 2024+. [arXiv](https://arxiv.org/abs/2411.02909)


C. Fan, J. Liu, **L. Lin***, J. Jia, R. Zhang, S. Mei, S. Liu.
Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning. Preprint, 2024+. [arXiv](https://arxiv.org/abs/2410.07163)


M. Celentano, Z. Fan, **L. Lin***, and S. Mei.
Mean-field variational inference with the TAP free energy: Geometric and statistical properties in linear models. Preprint, 2023+. [arXiv](https://arxiv.org/abs/2311.08442)

T. Ahn, **L. Lin***, S. Mei.
Near-optimal multiple testing in Bayesian linear models with finite-sample FDR control. Preprint, 2022+. [arXiv](https://arxiv.org/abs/2211.02778)




# Publications



**L. Lin***, K. Khamaru, M. J. Wainwright.
Semi-parametric inference based on adaptively collected data. **To appear in Annals of Statistics**, 2025. [arXiv](https://arxiv.org/abs/2303.02534)



**L. Lin**, J. Wu, S. M. Kakade, P. L. Bartlett, J. D. Lee.
Scaling Laws in Linear Regression: Compute, Parameters, and Data. **Advances in Neural Information Processing Systems (NeurIPS)**, 2024. [arXiv](https://arxiv.org/abs/2406.08466)



R. Zhang, **L. Lin***, Y. Bai, S. Mei.
Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning. **The First Conference on Language Modeling (COLM)**, 2024. [arXiv](https://arxiv.org/abs/2404.05868)


**L. Lin**, T. Zrnic. 
Plug-in Performative Optimization. **International Conference on Machine Learning (ICML)**, 2024. [arXiv](https://arxiv.org/abs/2305.18728)

**L. Lin**, Y. Bai, S. Mei.
Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining. **International Conference on Learning Representations (ICLR)**, 2024. [arXiv](https://arxiv.org/abs/2310.08566)

**L. Lin**, M. Ying, S. Ghosh, K. Khamaru, and C. Zhang.
Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference. **Advances in Neural Information Processing Systems (NeurIPS)**, 2023. [arXiv](https://arxiv.org/abs/2310.00532)


**L. Lin**, E. Dobriban.
What causes the test error? going beyond bias-variance via anova. **The Journal of Machine Learning Research**, 2021. [journal](https://www.jmlr.org/papers/v22/20-1211.html) [arXiv](https://arxiv.org/abs/2010.05170) 






